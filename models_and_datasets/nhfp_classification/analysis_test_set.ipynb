{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmol.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline.load('mhfp/trial_38')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmol.loaders import CSVLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fit_and_evaluate(pipeline):\n",
    "    train = CSVLoader(\"train.csv\",\n",
    "                        labels_fields=['C00073', 'C00078', 'C00079', 'C00082', 'C00235', 'C00341', 'C00353',\n",
    "                                        'C00448', 'C01789', 'C03506', 'C00047', 'C00108', 'C00187', 'C00148',\n",
    "                                        'C00041', 'C00129', 'C00062', 'C01852', 'C00049', 'C00135', 'C00223',\n",
    "                                        'C00509', 'C00540', 'C01477', 'C05903', 'C05904', 'C05905', 'C05908',\n",
    "                                        'C09762'],\n",
    "                        id_field=\"ids\", smiles_field=\"smiles\").create_dataset()\n",
    "    valid = CSVLoader(\"valid.csv\",\n",
    "                        labels_fields=['C00073', 'C00078', 'C00079', 'C00082', 'C00235', 'C00341', 'C00353',\n",
    "                                        'C00448', 'C01789', 'C03506', 'C00047', 'C00108', 'C00187', 'C00148',\n",
    "                                        'C00041', 'C00129', 'C00062', 'C01852', 'C00049', 'C00135', 'C00223',\n",
    "                                        'C00509', 'C00540', 'C01477', 'C05903', 'C05904', 'C05905', 'C05908',\n",
    "                                        'C09762'],\n",
    "                        id_field=\"ids\", smiles_field=\"smiles\").create_dataset()\n",
    "    test = CSVLoader(\"test.csv\",\n",
    "                        labels_fields=['C00073', 'C00078', 'C00079', 'C00082', 'C00235', 'C00341', 'C00353',\n",
    "                                        'C00448', 'C01789', 'C03506', 'C00047', 'C00108', 'C00187', 'C00148',\n",
    "                                        'C00041', 'C00129', 'C00062', 'C01852', 'C00049', 'C00135', 'C00223',\n",
    "                                        'C00509', 'C00540', 'C01477', 'C05903', 'C05904', 'C05905', 'C05908',\n",
    "                                        'C09762'],\n",
    "                        id_field=\"ids\", smiles_field=\"smiles\").create_dataset()\n",
    "\n",
    "    train_valid = train.merge([valid])\n",
    "    pipeline.fit(train_valid)\n",
    "    from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "    from deepmol.metrics import Metric\n",
    "\n",
    "\n",
    "    def macro_f1_score(y_true, y_pred):\n",
    "        return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    def macro_precision_score(y_true, y_pred):\n",
    "        return precision_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    def macro_recall_score(y_true, y_pred):\n",
    "        return recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "\n",
    "    results_test = pipeline.evaluate(test, metrics=[Metric(macro_f1_score), Metric(macro_precision_score), Metric(macro_recall_score)], per_task_metrics=False)\n",
    "    predictions = pipeline.predict(test)\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    test = pipeline.transform(test)\n",
    "    for i in range(predictions.shape[1]):\n",
    "        f1_score_task = f1_score(test.y[:, i], predictions[:, i])\n",
    "        recall_score_task = recall_score(test.y[:, i], predictions[:, i])\n",
    "        precision_score_task = precision_score(test.y[:, i], predictions[:, i])\n",
    "        f1_scores.append(f1_score_task)\n",
    "        recall_scores.append(recall_score_task)\n",
    "        precision_scores.append(precision_score_task)\n",
    "    \n",
    "    results_test[0]['f1_scores_std'] = np.array(f1_scores).std()\n",
    "    results_test[0]['recall_scores_std'] = np.array(recall_scores).std()\n",
    "    results_test[0]['precision_scores_std'] = np.array(precision_scores).std()\n",
    "\n",
    "    return results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_evaluate(pipeline=pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm_precursor_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
